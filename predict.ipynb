{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import pad\n",
    "import torch.nn.functional as F\n",
    "import codecs\n",
    "import json\n",
    "import re\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "seed = 2022\n",
    "vocab_dim = 512\n",
    "window_sizes = [3, 3, 5, 7]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def load_dictionaries():\n",
    "    \"\"\"返回每个词语的索引，词向量，以及每个句子所对应的词语索引\"\"\"\n",
    "    print(\"加载词典\")\n",
    "    w2indx_json = codecs.open(Config.w2indx_path, 'r', encoding=Config.encoding)\n",
    "    w2vec_json = codecs.open(Config.w2vec_path, 'r', encoding=Config.encoding)\n",
    "\n",
    "    w2indx = json.load(w2indx_json)\n",
    "    W2VEC = json.load(w2vec_json)\n",
    "    w2vec = dict()\n",
    "    for key, value in W2VEC.items():\n",
    "        w2vec[key] = np.asarray(value)\n",
    "\n",
    "    w2indx_json.close()\n",
    "    w2vec_json.close()\n",
    "\n",
    "    return w2indx, w2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def parse_dataset(combined):\n",
    "    \"\"\"将combined中的数据转换为索引表示\"\"\"\n",
    "    data = []\n",
    "    for sentence in combined:\n",
    "        new_txt = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                new_txt.append(w2indx[word])\n",
    "            except:\n",
    "                new_txt.append(0)\n",
    "        if len(new_txt) > maxlen:\n",
    "            new_txt=torch.Tensor(new_txt[:maxlen]).int()\n",
    "        elif len(new_txt) < maxlen:\n",
    "            new_txt = torch.Tensor(new_txt).int()\n",
    "            new_txt = pad(new_txt, (0, maxlen - new_txt.shape[0]))\n",
    "\n",
    "        data.append(new_txt)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "def get_embeddings(combined, embedding_weights):\n",
    "    \"\"\"根据combined获取embedding\"\"\"\n",
    "    inputs = [embedding_weights[sen] for sen in combined]\n",
    "    inputs = torch.Tensor(inputs)\n",
    "    print(inputs)\n",
    "    return inputs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "def regular(str_list: list) -> list:\n",
    "    \"\"\"\n",
    "    句子规范化，主要是对原始语料的句子进行一些标点符号的统一处理\n",
    "    \"\"\"\n",
    "    sen = []\n",
    "    for index, line in enumerate(str_list):\n",
    "        line = re.sub(r'…{1,100}', '…', line)\n",
    "        line = re.sub(r'\\.{3,100}', '…', line)\n",
    "        line = re.sub(r'···{2,100}', '…', line)\n",
    "        line = re.sub(r'\\.{1,100}', '。', line)\n",
    "        line = re.sub(r'。{1,100}', '。', line)\n",
    "        line = re.sub(r'？{1,100}', '？', line)\n",
    "        line = re.sub(r'!{1,100}', '！', line)\n",
    "        line = re.sub(r'！{1,100}', '！', line)\n",
    "        line = re.sub(r'~{1,100}', '～', line)\n",
    "        line = re.sub(r'～{1,100}', '～', line)\n",
    "        line = re.sub(r'\\d*\\.\\d+|\\d+', '1', line)  # 将所有数字都替换成1\n",
    "        sen.append(line)\n",
    "    return sen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "def get_inputs(str_list: list, embedding_weights):\n",
    "    # 句子规范化\n",
    "    str_list = regular(str_list)\n",
    "    # 分词处理\n",
    "    combined = []\n",
    "    for s in str_list:\n",
    "        words = jieba.lcut(s)\n",
    "        words = \" \".join(words)\n",
    "        combined.append(words)\n",
    "\n",
    "    # 将词转换成对应的id\n",
    "    combined = parse_dataset(str_list)  # 将combined中的数据转换为索引表示\n",
    "    combined = nn.utils.rnn.pad_sequence(combined, batch_first=True, padding_value=0)\n",
    "    print(combined.shape)\n",
    "\n",
    "    # 将词id转换成对应的embedding\n",
    "    inputs = get_embeddings(combined, embedding_weights)\n",
    "    print(inputs.shape)\n",
    "\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "def Print(inputs, outputs):\n",
    "    emo_dict = {0: 'null', 1: 'like', 2: 'sad', 3: 'disgust', 4: 'angry', 5: 'happy'}\n",
    "    outputs = outputs.argmax(axis=1).cpu()\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        print(f'{inputs[i]} --> {emo_dict[outputs[i].item()]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "                nn.Sequential(nn.Conv1d(in_channels=vocab_dim,\n",
    "                                        out_channels=256,\n",
    "                                        kernel_size=h),\n",
    "                              nn.Dropout(0.2),\n",
    "                              nn.BatchNorm1d(num_features=256),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool1d(kernel_size=maxlen-h+1))\n",
    "                     for h in window_sizes\n",
    "                    ])\n",
    "        self.fc = nn.Linear(in_features=256 * len(window_sizes),\n",
    "                            out_features=6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # inputs = [batch, maxlen, vocab_dim]\n",
    "\n",
    "        # SpatialDropout1D\n",
    "        x = x.permute(0, 2, 1)   #  [batch, vocab_dim, maxlen]\n",
    "        x = F.dropout2d(x, 0.3, training=self.training)\n",
    "        x = x.permute(0, 2, 1)   # back to  [batch, maxlen, vocab_dim]\n",
    "\n",
    "        # batch_size x text_len x embedding_size  -> batch_size x embedding_size x text_len\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        out = torch.cat([conv(x).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "def predict(str_list, embedding_weights):\n",
    "    print('loading model......')\n",
    "    model = TextCNN()\n",
    "    model.load_state_dict(torch.load(\"model/model.pth\")['state_dict']) # 只保存了训练参数\n",
    "    model.cuda()\n",
    "\n",
    "    # 处理输入\n",
    "    inputs = get_inputs(str_list, embedding_weights)\n",
    "    inputs = inputs.cuda()\n",
    "\n",
    "    # 进行预测\n",
    "    model.eval()\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 输出结果\n",
    "    Print(str_list, outputs)\n",
    "    return outputs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载词典\n"
     ]
    }
   ],
   "source": [
    "w2indx, w2vec = load_dictionaries()\n",
    "n_symbols = len(w2indx) + 1\n",
    "embedding_weights = np.zeros((n_symbols, vocab_dim))\n",
    "for word, index in w2indx.items():  # 从索引为1的词语开始，对每个词语对应其词向量\n",
    "    embedding_weights[index, :] = w2vec[word]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model......\n",
      "torch.Size([7, 20])\n",
      "tensor([[[ 3.8169e-01, -4.0005e-01,  2.9346e-01,  ..., -2.2200e+00,\n",
      "           9.3815e-02, -7.7787e-01],\n",
      "         [-6.3990e-01,  6.0148e-02,  1.3081e+00,  ..., -1.3306e+00,\n",
      "          -2.8541e-01,  3.2685e-01],\n",
      "         [-4.1571e-02, -6.4343e-01,  7.6042e-01,  ..., -1.4898e+00,\n",
      "          -3.7161e-01, -1.8120e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-6.8756e-01,  4.7396e-01,  1.1422e+00,  ..., -2.0392e+00,\n",
      "          -1.8019e-01, -1.9962e+00],\n",
      "         [-1.3168e-01,  1.2774e+00,  1.6794e-01,  ...,  3.3911e-01,\n",
      "           1.5143e-01, -1.0711e+00],\n",
      "         [-1.3465e+00,  1.5103e+00,  5.1551e-01,  ...,  6.1945e-01,\n",
      "           3.2719e-01, -1.1235e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2191e+00,  9.0389e-01,  2.1578e-01,  ..., -1.2494e+00,\n",
      "           1.0074e+00, -1.4185e+00],\n",
      "         [ 1.2191e+00,  9.0389e-01,  2.1578e-01,  ..., -1.2494e+00,\n",
      "           1.0074e+00, -1.4185e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.2529e-02,  1.0247e+00,  1.8153e-01,  ..., -1.7133e-01,\n",
      "           9.3638e-01, -8.1805e-01],\n",
      "         [-5.3231e-01,  1.5750e+00, -4.3047e-01,  ..., -5.1156e-01,\n",
      "          -8.7721e-01, -8.5980e-01],\n",
      "         [ 3.8169e-01, -4.0005e-01,  2.9346e-01,  ..., -2.2200e+00,\n",
      "           9.3815e-02, -7.7787e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.1514e-01, -9.6326e-01, -3.4245e-01,  ..., -8.4819e-01,\n",
      "          -6.4394e-01,  1.8072e-02],\n",
      "         [ 3.1315e-01, -5.6886e-01, -1.4181e+00,  ..., -1.3017e+00,\n",
      "           1.0964e+00, -8.6804e-04],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.4254e-01,  5.7158e-01, -3.3156e-01,  ..., -1.6476e+00,\n",
      "          -6.8799e-01,  1.3486e-01],\n",
      "         [ 6.2092e-01, -2.0702e+00, -4.7543e-01,  ...,  1.5412e-01,\n",
      "          -2.8663e-01,  1.4532e+00],\n",
      "         [ 6.2092e-01, -2.0702e+00, -4.7543e-01,  ...,  1.5412e-01,\n",
      "          -2.8663e-01,  1.4532e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]])\n",
      "torch.Size([7, 20, 512])\n",
      "一只小泰迪 --> null\n",
      "你想干什么？! --> angry\n",
      " 猫猫真可爱！ --> like\n",
      "请问您今天要来点兔子吗？ --> null\n",
      "喜欢一个人是隐藏不住的。 --> like\n",
      "傻逼 --> angry\n",
      "今天天气真好！ --> like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
     ]
    }
   ],
   "source": [
    "str_list = ['一只小泰迪', '你想干什么？!', ' 猫猫真可爱！', '请问您今天要来点兔子吗？', '喜欢一个人是隐藏不住的。', '傻逼', \"今天天气真好！\"]\n",
    "outputs = predict(str_list, embedding_weights)  # 预测的是一个列表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
